from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.llms import Ollama
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import json
import os


class RAGSystem:
    def __init__(self, data_path="data/sample_data.json", vectorstore_path="./vectorstore"):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.data_path = data_path
        self.vectorstore_path = vectorstore_path
        self.embeddings = None
        self.llm = None
        self.vectorstore = None
        self.qa_chain = None

        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        self._setup()

    def _setup(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì„¤ì •"""
        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("ğŸ“Š ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (ì²˜ìŒì—” ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ ê±¸ë¦¼)")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

        # 2. Ollama LLM ì„¤ì •
        print("ğŸ¦™ Ollama ì—°ê²° ì¤‘...")
        self.llm = Ollama(
            model="llama3.2:3b",
            temperature=0.7,
        )
        print("âœ… Ollama ì—°ê²° ì™„ë£Œ!")

        # 3. ë²¡í„° DB ë¡œë“œ ë˜ëŠ” ìƒì„±
        if os.path.exists(self.vectorstore_path):
            print("ğŸ“‚ ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì¤‘...")
            self.vectorstore = Chroma(
                persist_directory=self.vectorstore_path,
                embedding_function=self.embeddings
            )
            print("âœ… ë²¡í„° DB ë¡œë“œ ì™„ë£Œ!")
        else:
            print("ğŸ”¨ ìƒˆ ë²¡í„° DB ìƒì„± ì¤‘...")
            self._create_vectorstore()

        # 4. QA ì²´ì¸ ìƒì„±
        self._create_qa_chain()
        print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n")

    def _create_vectorstore(self):
        """ë°ì´í„°ì—ì„œ ë²¡í„° DB ìƒì„±"""
        # ë°ì´í„° ë¡œë“œ
        print(f"ğŸ“– ë°ì´í„° ë¡œë“œ ì¤‘: {self.data_path}")
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… {len(data)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

        # í…ìŠ¤íŠ¸ ë¶„í• 
        print("âœ‚ï¸  í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            length_function=len,
        )

        texts = []
        metadatas = []

        for item in data:
            # ì œëª©ê³¼ ë‚´ìš© í•©ì¹˜ê¸°
            full_text = f"ì œëª©: {item['title']}\n\n{item['content']}"

            # ì²­í¬ë¡œ ë¶„í• 
            chunks = text_splitter.split_text(full_text)

            for chunk in chunks:
                texts.append(chunk)
                metadatas.append({
                    'source': item['url'],
                    'title': item['title']
                })

        print(f"âœ… ì´ {len(texts)}ê°œ ì²­í¬ ìƒì„±")

        # ë²¡í„° DB ìƒì„±
        print("ğŸ”® ë²¡í„° DB ìƒì„± ì¤‘... (ì‹œê°„ ì¢€ ê±¸ë¦¼)")
        self.vectorstore = Chroma.from_texts(
            texts=texts,
            embedding=self.embeddings,
            metadatas=metadatas,
            persist_directory=self.vectorstore_path
        )
        self.vectorstore.persist()
        print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")

    def _create_qa_chain(self):
        """QA ì²´ì¸ ìƒì„±"""
        # í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """ë‹¹ì‹ ì€ ë™ì–‘ëŒ€í•™êµ í•™ìƒë“¤ì„ ë•ëŠ” ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ ê·œì¹™:
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”
3. ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
4. ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”
5. ë‹µë³€ ëì— ì¶œì²˜ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”

ë‹µë³€:"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        # QA ì²´ì¸ ìƒì„±
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰
            ),
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt}
        )

    def ask(self, question):
        """ì§ˆë¬¸í•˜ê¸°"""
        print(f"\nâ“ ì§ˆë¬¸: {question}")
        print("ğŸ” ê²€ìƒ‰ ì¤‘...")

        result = self.qa_chain({"query": question})

        answer = result['result']
        sources = result['source_documents']

        print(f"ğŸ’¬ ë‹µë³€: {answer}\n")

        # ì¶œì²˜ í‘œì‹œ
        if sources:
            print("ğŸ“š ì¶œì²˜:")
            seen_sources = set()
            for doc in sources:
                source = doc.metadata.get('source', 'Unknown')
                title = doc.metadata.get('title', 'Unknown')
                if source not in seen_sources:
                    print(f"  - {title}: {source}")
                    seen_sources.add(source)

        return {
            'answer': answer,
            'sources': [
                {
                    'title': doc.metadata.get('title', 'Unknown'),
                    'url': doc.metadata.get('source', 'Unknown')
                }
                for doc in sources
            ]
        }

    def reset_vectorstore(self):
        """ë²¡í„° DB ì´ˆê¸°í™” (ìƒˆ ë°ì´í„° íˆ¬ì… ì‹œ ì‚¬ìš©)"""
        import shutil
        if os.path.exists(self.vectorstore_path):
            shutil.rmtree(self.vectorstore_path)
            print("ğŸ—‘ï¸  ê¸°ì¡´ ë²¡í„° DB ì‚­ì œ ì™„ë£Œ")
        self._create_vectorstore()
        self._create_qa_chain()
        print("âœ… ìƒˆ ë²¡í„° DB ìƒì„± ì™„ë£Œ")


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = RAGSystem()

    # ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
    print("=" * 60)
    print("ë™ì–‘ëŒ€í•™êµ AI ë„ìš°ë¯¸ (ì¢…ë£Œ: 'quit' ì…ë ¥)")
    print("=" * 60)

    while True:
        question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")

        if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        if not question.strip():
            continue

        rag.ask(question)